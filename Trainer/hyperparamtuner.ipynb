{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "\n",
    "# Hugging Face Hub import\n",
    "\n",
    "# Diffusers-specific imports\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "\n",
    "# Custom modules\n",
    "from models import UNETLatentEdgePredictor, SketchSimplificationNetwork\n",
    "from pipeline import SketchGuidedText2Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:58:59.108161Z",
     "iopub.status.busy": "2024-03-12T08:58:59.107556Z",
     "iopub.status.idle": "2024-03-12T08:58:59.112413Z",
     "shell.execute_reply": "2024-03-12T08:58:59.111442Z",
     "shell.execute_reply.started": "2024-03-12T08:58:59.108134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configure and load sketch simplification network \n",
    "\n",
    "sketch_simplifier = SketchSimplificationNetwork().to(device)\n",
    "sketch_simplifier.load_state_dict(torch.load(\"models-checkpoints/model_gan.pth\"))\n",
    "\n",
    "sketch_simplifier.eval()\n",
    "sketch_simplifier.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Stable Diffusion Pipeline\n",
    "stable_diffusion_1_5 = \"benjamin-paine/stable-diffusion-v1-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_diffusion=StableDiffusionPipeline.from_pretrained(\n",
    "    stable_diffusion_1_5,\n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None  # Skip the safety checker if it's not required\n",
    ")\n",
    "vae = stable_diffusion.vae.to(device)\n",
    "unet = stable_diffusion.unet.to(device)\n",
    "tokenizer = stable_diffusion.tokenizer\n",
    "text_encoder = stable_diffusion.text_encoder.to(device) \n",
    "\n",
    "vae.eval()\n",
    "unet.eval()\n",
    "text_encoder.eval()\n",
    "\n",
    "text_encoder.requires_grad_(False)\n",
    "unet.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load U-Net latent edge predictor\n",
    "checkpoint = torch.load(\"models-checkpoints/unet_latent_edge_predictor_checkpoint.pt\",map_location=torch.device('cpu'))\n",
    "\n",
    "LEP_UNET = UNETLatentEdgePredictor(9320, 4, 9).to(device)\n",
    "LEP_UNET.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "LEP_UNET.eval()\n",
    "LEP_UNET.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T08:59:39.675602Z",
     "iopub.status.busy": "2024-03-12T08:59:39.675133Z",
     "iopub.status.idle": "2024-03-12T08:59:39.681085Z",
     "shell.execute_reply": "2024-03-12T08:59:39.680066Z",
     "shell.execute_reply.started": "2024-03-12T08:59:39.675549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy \n",
    "# Set Scheduler\n",
    "noise_scheduler = DDIMScheduler(\n",
    "        beta_start = 0.00085,\n",
    "        beta_end = 0.012,\n",
    "        beta_schedule = \"scaled_linear\",\n",
    "        num_train_timesteps = 1000,\n",
    "        clip_sample = False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T09:03:10.472809Z",
     "iopub.status.busy": "2024-03-12T09:03:10.471844Z",
     "iopub.status.idle": "2024-03-12T09:03:10.489488Z",
     "shell.execute_reply": "2024-03-12T09:03:10.488781Z",
     "shell.execute_reply.started": "2024-03-12T09:03:10.472773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize Text-guided Text-to-Image synthesis pipeline\n",
    "import tqdm\n",
    "\n",
    "pipeline = SketchGuidedText2Image(stable_diffusion_pipeline = stable_diffusion, \n",
    "                                  unet = unet, vae = vae, \n",
    "                                  text_encoder = text_encoder, \n",
    "                                  lep_unet = LEP_UNET, scheduler = noise_scheduler, \n",
    "                                  tokenizer = tokenizer,\n",
    "                                  sketch_simplifier = sketch_simplifier,\n",
    "                                  device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T09:03:51.073192Z",
     "iopub.status.busy": "2024-03-12T09:03:51.072823Z",
     "iopub.status.idle": "2024-03-12T09:04:19.214421Z",
     "shell.execute_reply": "2024-03-12T09:04:19.213437Z",
     "shell.execute_reply.started": "2024-03-12T09:03:51.073160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def tune_hyperparameters(pipeline, prompt, edge_maps, seed=None):\n",
    "    \"\"\"\n",
    "    Performs a grid search over hyperparameters for the inference process.\n",
    "    \n",
    "    Parameters:\n",
    "      pipeline: an instance of your SketchGuidedText2Image pipeline.\n",
    "      prompt: list or string prompt.\n",
    "      edge_maps: list of PIL Images for edge maps.\n",
    "      seed: optional seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "      results: a list of dictionaries, each containing the hyperparameters and the output images.\n",
    "    \"\"\"\n",
    "    # Define the grid of hyperparameters to explore\n",
    "    num_inference_timesteps_list = [12,15,20]  # using 12 steps for training constraints\n",
    "    classifier_guidance_strength_list = [4, 6, 8]  # try a few values lower than the demoâ€™s 8\n",
    "    sketch_guidance_strength_list = [0.5, 1.0, 0.7, 1.6]  # scaled down values relative to the original demo\n",
    "    guidance_steps_perc_list = [0.5]  # keeping relative percentage the same\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # Loop over all combinations\n",
    "    for (num_steps, cls_str, skt_str, gd_perc) in itertools.product(\n",
    "            num_inference_timesteps_list,\n",
    "            classifier_guidance_strength_list,\n",
    "            sketch_guidance_strength_list,\n",
    "            guidance_steps_perc_list):\n",
    "        \n",
    "        print(f\"Testing: num_steps={num_steps}, classifier={cls_str}, sketch={skt_str}, guidance%={gd_perc}\")\n",
    "        \n",
    "        # Call the Inference function from your pipeline\n",
    "        output = pipeline.Inference(\n",
    "            prompt=prompt,\n",
    "            num_images_per_prompt=1,\n",
    "            edge_maps=edge_maps,\n",
    "            negative_prompt=None,\n",
    "            num_inference_timesteps=num_steps,\n",
    "            classifier_guidance_strength=cls_str,\n",
    "            sketch_guidance_strength=skt_str,\n",
    "            seed=seed,\n",
    "            simplify_edge_maps=False,\n",
    "            guidance_steps_perc=gd_perc,\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            \"num_steps\": num_steps,\n",
    "            \"classifier_guidance_strength\": cls_str,\n",
    "            \"sketch_guidance_strength\": skt_str,\n",
    "            \"guidance_steps_perc\": gd_perc,\n",
    "            \"result\": output  # output contains keys like \"generated_image\" and \"edge_map\"\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Make sure your pipeline instance is already created and configured as in your demo\n",
    "prompt = [\"Lego car\"]\n",
    "edge_maps = [Image.open(\"Lego_256x256/sketch/Car-1.jpg/sketchs32strokes_Car-1.jpg\")]\n",
    "seed = 1000\n",
    "\n",
    "inverse_diffusion = pipeline.Inference(\n",
    "    prompt=[\"Lego car \"],\n",
    "    num_images_per_prompt=1,\n",
    "    edge_maps=edge_maps,\n",
    "    negative_prompt=None,\n",
    "    num_inference_timesteps=50,\n",
    "    classifier_guidance_strength=8,\n",
    "    sketch_guidance_strength=1.6,\n",
    "    seed=seed,\n",
    "    simplify_edge_maps=False,\n",
    "    guidance_steps_perc=0.5,\n",
    ")\n",
    "\n",
    "# Run the hyperparameter tuner\n",
    "tuning_results = tune_hyperparameters(pipeline, prompt, edge_maps, seed=seed)\n",
    "\n",
    "# Visualize the outputs\n",
    "n_results = len(tuning_results)\n",
    "fig, axs = plt.subplots(1, n_results, figsize=(4 * n_results, 4))\n",
    "if n_results == 1:\n",
    "    axs = [axs]\n",
    "for ax, res in zip(axs, tuning_results):\n",
    "    # Assume the generated image is under the key \"generated_image\" and is a list of PIL images\n",
    "    generated_img = res[\"result\"][\"generated_image\"][0]\n",
    "    ax.imshow(generated_img)\n",
    "    ax.axis(\"off\")\n",
    "    title = (f\"Steps: {res['num_steps']}\\n\"\n",
    "             f\"Cls: {res['classifier_guidance_strength']}\\n\"\n",
    "             f\"Sketch: {res['sketch_guidance_strength']}\\n\"\n",
    "             f\"Perc: {res['guidance_steps_perc']}\")\n",
    "    ax.set_title(title)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4178065,
     "sourceId": 7218894,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4266125,
     "sourceId": 7436335,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4573097,
     "sourceId": 7808408,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4572523,
     "sourceId": 7819660,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4581456,
     "sourceId": 7819703,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
